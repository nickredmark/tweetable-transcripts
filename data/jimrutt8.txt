Jim Rutt: Howdy! This is Jim Rutt, and this is The Jim Rutt Show. Today’s guest is Jordan Hall, a good friend as well as one of the broadest and deepest thinkers around about the future of society, economics, politics and more.

Jordan Hall: Thanks Jim. It’s very nice to be here.

Jim Rutt: Great to have you. Prior to setting out to save the world from itself, Jordan was a successful Tech Exec and Tech Investor. Usually, I spend about 10 hours preparing for each guest and carefully craft a set of topics to keep the conversation moving but tonight at Jordan’s request, we’re going to do something different. In this episode, he and I are going to interact in a pretty freeform fashion.

Jim Rutt: Jordan has a concept of thinking versus simulated thinking and we’re committed tonight to try and do thinking. Jordan, why don’t you start off by telling the audience about the difference between thinking and simulated thinking?

Jordan Hall: Interesting. Okay. I guess to begin we can maybe make the distinction that I think is pretty common in the literature between something that I’ve called habit mode and maybe something you might call contemplation or seeking mode. The notion here is that the way that the human mind brain works is there’s a portion of your awareness that is very open and exploring and endeavoring to bias in the direction of perception and to the portion of the way that your brain works that when particular behaviors or functions have been pretty well understood are reduced to habits and therefore extremely efficient. The classic example is that as you’ve become quite skillful at driving, you can find yourself doing the very complicated function of driving and doing many other things at the same time. Certainly having a conversation of course if you’re millennial, you’re probably texting.

Jordan Hall: The first is just to recognize that having both of those modes is part of just being a healthy person and healthy mind and that each one has different strengths and weaknesses if you’re endeavoring to do your accounting, most of the time you’re actually trying to do some function of habit mode to just doing the raw math for example. You don’t want to be contemplating deep with a very nature number in that context. By contrast for example if you are hunting, particularly if you’re hunting on the move, if you’re tracking, a large portion of your awareness will actually have to be pretty wide open and sensitive to signals that may not be obvious signals. It’s even more so the case if you’re not just hunting but are in say, a combat environment where the opponent is as adept at simulating and/or obfuscating signal as you are trying to tease it out.

Jordan Hall: The concept of simulated thinking then what it does is it takes this notion of saying habit mind and notices that a large portion of the culture that we’ve been raised in and this was going on for hundreds of years, well frankly quite artificial and quite optimized. We go to school and we very quickly, somewhere around 3rd or 4th Grade, learned that understanding what’s being taught is not really the nature of the Game But rather being able to repeat back the correct answers with precision and speed is the nature of the game. We begin to actually use more and more of a habit mind-like approach to cover more and more aspects of what thinking might be.

Jordan Hall: There’s a proposition that I’m making when I make this distinction that there’s a threshold where habit mind actually begins to take itself as the whole of thinking. We have so many different schema that have been loaded into our brain on how to respond to different conversational gambits or events in our environment then we are in fact almost exclusively acting out of habit and almost not at all actually using the part of mind to truly, deeply contemplate what’s happening in front of us and the proposition is that that’s a trap, that we would find ourselves in simulated thinking it can be very, very effective in circumstances that are what’s called ordinary like say you’re in school. That can be extremely ineffective when you’re actually in a novel environment much worse than just a regular old habit mind because at least habit mind is more fluidly related to seeking mind.

Jim Rutt: Yeah. What you call simulated thinking screams at me about much, not all, of my experience in big corporate America. Unlike you, I actually did work for big companies for quite a number of years and the number of conversations that could only be called simulated thinking actually dominates, I would say, most of the interactions in large corporations and it’s why they fairly often get caught with their pants down. The example I like to give is in my hometown of Washington D.C. We had a pretty big, pretty strong regional home improvements Shane called Hechinger. They had 120 stores over three or four states and they saw Home Depot and Lowe’s coming for 20 years and one of the last places Home Depot and Lowe’s showed up was in the D.C. area because they figured Hechinger’s was a pretty strong, entrenched incumbent but the truth was Hechinger’s had not improved their game in those 20 years and within a year of Home Depot showing up, Hechinger’s was bankrupt.

Jim Rutt: The only thing I can assume is that for 20 years they were doing simulated thinking because they could have responded. The Home Depot mix was a little smarter, a little better than Hechinger’s but not by a light years but I can just see it now, they were involved in basically jerking each other off in the conventional fashion for 20 years hoping nothing would happen or at least that their pensions would vest. Then when the opponent actually showed up, they collapsed. This happens again and again and again. In fact, part of my role in corporate America and probably the only reason I was tolerated in corporate America, not thrown out on my ass was I think I had a skill for crafting spaces where people could engage in thinking and that’s why they put up with my obnoxiousness and bomb-throwing because they knew, at some higher level, that thinking was what’s going to save them particularly during that big year of transition. I worked a good part of my career in the publishing industry as we transition from CD ROMs and even books to proprietary online and then the internet.

Jim Rutt: If you didn’t have somebody thinking, you were going to lose that race. There’s a classic example of where if you’re not fluid, if you’re just hitting the ping pong ball back and forth like so many banal conversations in corporate America, you’re not going to make the change fast enough and you’re going to be Hechinger’s not Home Depot. Yeah, I think that’s a wonderful construction and I’ve been taking to stealing it and using it with credit where appropriate because it really does say something about what’s seriously wrong about our society today particularly in this CPAC of exponential change.

Jim Rutt: Which I think brings us to the next topic, one that I know you want to talk about which is … Jordan is pretty well-known for saying the end is near in the current game in the status quo whether it’s eco side where we kill our environment or a financial collapse plus a civil war, throw in an epidemic or two, maybe mass insanity brought on by the internet. Anyway, the game we are currently, Jordan says, will end soon. He calls the current game Game A. Why don’t you to tell us about what is Game A and why you think it’s getting near the end of its time?

Jordan Hall: Okay. I think that the opening with simulated thinking actually provides a nice context for walking into the broader notion of Game A because the two are, I think, meaningfully related. If you think about the kind of circumstances that tend to give rise to simulated thinking and maybe just sort of generalize and think about the various kinds, predominantly when one finds oneself was called relatively far from nature, relatively far from the uncertain or from the, well, from complexity quite precisely, simulated thinking can tend to settle in. To use the Game of Thrones metaphor, when you’re in King’s Landing simulated thinking actually tends to be a very good strategy. When you’re in the North, winter or more specifically nature, will kill you if you’re simulated thinking so there’s a pressure there.

Jordan Hall: Okay. The journey to formulating Game A has frankly been quite long. It began with just taking a look at very concrete things like the financial crisis of 2008 and why exactly, even as early as 2008, it was to me at least evidence of political systems in the West we’re beginning the process of some quite significant breakdown. For me the journey was one of just trying to look more and more deeply at, let’s say, fundamental. Is there anything fundamental about this, because if we want to figure out how to solve a problem, we’d like to figure out how to actually get down to the roots of the problem and tear it out from the roots and most endeavors, thus far at least, to solve the problem have, from my perspective, been [inaudible 00:08:38], they’ve been patches, they’ve been modifications and additions to some sort of more basic architecture and haven’t therefore gone all the way down.

Jordan Hall: I’ve spent quite some time endeavoring to go down. The way that I tell the story most often and I think in a fashion at least is the most understandable is somewhat historical. Can I go in that direction? Does that make sense?

Jim Rutt: Absolutely. Well, we’re thinking here. We’re not stimulated thinking. Go whatever direction you think is useful.

Jordan Hall: All right. Here’s the story that seems to me to work pretty well and just as a caveat to everybody out there, I will take full responsibility for what I’m about to say and recognizing that we are definitely in thinking space meaning it’s quite likely the most of what I’m saying is at best rough and a sizeable fraction was just flat-out wrong. This is an effort to do something novel and I’ll put my neck on the line.

Jordan Hall: There are many other people who’ve been thinking about this thing and maybe I’ll reference very specific contributions that they’ve made that are substantially more rigorous than I’m about to say.

Jordan Hall: The proposition is that we have essentially, so far, in the arc of human history, three basic serious moves. Almost like three points on the line. The first we could just broadly point to as the emergence of Homo sapiens sapiens or whatever it is that transitions humans from being more or less like chimpanzees to being more or less like modern humans. The second move is the one that I’ve want to point some time out right now which seems to be in the order of about 75,000 years ago and perhaps we may even just call it the upper Paleolithic transition. Something happened in that timeframe that can be broadly looked at as being significant. The proposition that I would put forward is that this is the point at which Homo sapiens sapiens was able to perfect a particular, what I’ll call, a collective intelligence toolkit, a way of unleashing a particular capacity that was latent or ambient in social animals and in increasingly tribal and increasingly pro-social animals as you move through the evolutionary tree until finally, Homo sapiens sapiens had the right stuff.

Jordan Hall: By the way, under the right circumstances to have to find in the fitness landscape a location of this particular collective intelligence capacity, I’ll just name that tribal coherence. This is a way that a group of people can come together. In this case, it’s almost strictly lineage balance. This group of people is all of which are genetically related; first, second, third generation and all of whom have always lived in exactly the same culture as everyone else. It’s a very tightly bound group and nonetheless, has been able to achieve a particular capacity to work together. They gave rise to this unique human ability to engage in niche transition or the ability to not be bound to a particular biological ecosystem where moving from one niche to another niche is extraordinarily unlikely to be successful because you’re just going to have to evolve in good old-fashioned biological time.

Jordan Hall: Actually being able to use cultural evolution to move from the coast line to across out of Africa and then down and through all the various niches of the entire world and relatively rapidly like in order of two or three generations become a peak predator by developing cultural artifacts that enable that for survival and thriving in a particular niche. That’s the first major move, the development of tribal coherence and the explosion of this novel human capacity using tribal coherence to engage in niche transition.

Jim Rutt: Question for you, Jordan. At this point, is it actually tribal or is it still at the hunter-gatherer band level?

Jordan Hall: To be very precise, it’s the hunter-gatherer band level and in fact specifically, somewhere within the notion of Dunbar.

Jim Rutt: For people who don’t know about the Dunbar number this is something that Jordan and I have used in our thinking for a long time. What was his name? Robin Dunbar?

Jordan Hall: Yeah, Robin Dunbar.

Jim Rutt: Yeah. Robin Dunbar did a bunch of research and found that for current humans, we typically have more than 150 real friends then he went through anthropological literature and he found that in modern hunter-gatherer bands or recent almost modern ones that almost survived to the present. It was extremely uncommon to have a band, one of these extended lineages not all necessarily related, they always took people in and people left, very unusual for them to be bigger than a 150. As they approach 150, they tended to fractionate into two units and new people go I’m gone until they got that 150 and it happened again and again. I just want to make that clear that we’re talking not tribal here, which is the next step, but hunter-gatherer.

Jordan Hall: Yeah, yeah. You’re right. In fact, if one is familiar with the distinction then band is exactly right. I tend to use tribal because almost nobody’s familiar with the distinction but thank you. In fact you actually point to the next stage. More or less what happens then, if we fast forward, we see this diaspora of humanity operating at this band level in these relatively small tight-knit groups. As the population increases beyond a certain threshold, the groups separate and move and so this drives the spread and over a period of 30 or so thousand years, managed to cover the entire globe. Here then begins the pressure of the next stage which may in fact be at the Neolithic transition.

Jordan Hall: But in any event, something begins to happen where the primary pressure in the niche that you’re in is no longer nature, it’s actually other people. Where the ability to just move to a new location that is now empty and open, even maybe a relatively rough location like say, moving from a nice grassland into the desert because the grassland is now full but we can build a technology to allow us to survive in the desert. Even the deserts are relatively full of people. Enough. All right. They’re not full of people that moving into these locations is now no longer easy and so now a pressure begins to build. This pressure, I imagine over a very long period of time thousands of years, tens of thousands of years, different solutions to the pressure would pop up.

Jordan Hall: As we look at the anthropological story, we see tribal structures pop up, tribal in the more formal sense that a larger in scale, and actually do show a capacity to do things like gather and concentrate wealth. We’ll see grave sites that what appear to be aristocratic-like individuals who have concentrations of wealth well in advance of Bronze Age civilization for example. There’s an exploration and exploration, classic evolutionary search function looking for something that is more stable and more complete until eventually there is a discovery and, as we now know, more of a seven distinct locations around the world but in the Fertile Crescent once maybe three times of this thing that I will now call Game A, which is a new collective intelligence toolkit that includes what John Vervaeke would call Psycho-technology.

Jordan Hall: It’s a set of psycho-technology that give rise to a unique capacity and particularly a unique capacity in the context of the band level of collective intelligence. It can beat bands categorically. Game A, fundamentally, is about being able to solve ultimately three primary problems. It still has to be able to solve the problem of how you survive in nature so it still has to be able to gather people together such that they can extract resources from nature so as to provide for the well-being of the group.

Jordan Hall: Now though it has to be able to survive competition with other human groups and ideally to be victorious in competition with other human groups. As we will discover as a third piece, it has to actually be able to survive internal defection as the population begins to grow well beyond the Dunbar number.

Jordan Hall: Game A is a collection of psycho-technology. It is a collective intelligence toolkit that is the solution to the question of how does one go about satisfying those three problems. Of course, it’s continually been developing over time as initially the first order Game A civilizations were quite successful in being able to expand and absorb their nearest neighbors. We have now pretty strong evidence of what looks like quite a catastrophe in the Y-chromosome lineage somewhere around this timeframe, somewhere on the Neolithic transition where something on the order of 90% of all male lines were extinguished. I would propose that that’s the story, the story of Game A, wherever it was discovered, the neighbors got more slaughtered the women became part of the Game A structure, the civilization began to expand and then the neighbors either had to run away, found themselves part of the emerging civilization or had to up their Game And become a new Game A player. The relationship, for example, between Samaria and the Acadians is an example of that last piece.

Jordan Hall: It seems like a good place to pause there and see where we are in the story.

Jim Rutt: Okay. Is this the question about the technology? Do you see this transition happening around the time of the development of agriculture and larger settlements or is this a little earlier than that?

Jordan Hall: My sense is that it’s right up at this threshold of and the development of agriculture is part of the toolkit, probably a little bit later than its beginning. As you begin to have success in Game A, one of the first problems you run into is you’re beginning to have a population base that is larger than can be reasonably handled by hunting and gathering particularly because the other technologies of Game A tend to be not as easily mobile so you have to be a little bit more sedentary, which then leads to a recursive search on how do we begin to use … What was in fact a relatively robust agricultural toolkit that had already been developed over a period of time, how do we use these now with a little bit more urgency? You kind of popped through the Agricultural Revolution in that timeframe.

Jordan Hall: Just to hold that for a second, if you run all the way back to the story of the emergence of homo sapiens sapiens, you actually see a very analogous search function where you needed to be able to, for example, figure out, and I mean this I’m obviously anthropomorphizing all of these functions, but figure out the problem of say, grandmothers and you had to figure out the problem of radically increasing both the possibility and the survivability of increased male attention in parenting, and you had to figure out how to increase or really quite significantly change the gestation and early childhood birthing because of course, as humans were beginning to grow larger and larger crania, the physical capacity of women to give birth was limited and so you had these extreme neotenous children which required grandmothers and required more male resources to support [inaudible 00:18:36].

Jordan Hall: All of these different problems have to be solved and any one of which is just a complete waste of time. There’s this really challenging issue of getting a multivariate, complex system to actually nudging each one of these different pieces almost randomly but just enough to create enough possibility to move the whole thing closer and closer to this basin of attraction. Once it hits the basin, there’s a pop and suddenly, “Okay. We now have enough of the pieces in plates that a whole new thing kicks off called humanity and we move forward.”

Jordan Hall: The same thing happening here where you’ve got everything from moving in to writing, the presencing of symbolic language on the top of or orality and you have the capacity to begin really expanding technology and agriculture, which included things like the ability to do astronomy, modeling time and being able to actually use constructs of time to be able to notice when seasons are going to come and go, when rivers were going to flood, et cetera, et cetera. There’s a whole bunch of different things that have to come together, no one of which is enough to cause enough density and stability to land but once the complex hits, bam! You have this new thing and it begins to expand in the world because it now can, was notably, it can scale. It can actually grow the number of human beings that are participating in a pro-social in-group vastly beyond the Dunbar limit.

Jim Rutt: I like to make a couple comments about that. If we think about this, yes it makes the transition but unfortunately, it’s a one-way transition. The densities get way higher than could support foragers. Once a society makes the transition to settle to agriculture and such, it cannot peacefully go back to being a forager society. We know in some cases where they’ve collapsed and been big die outs and they’ve gone back to being foragers but essentially in a positive mode, it’s a one-way ratchet.

Jim Rutt: The other part, and this as you probably know, there are many people who believe the invention of this settled agriculture Game A complex was actually a great tragedy at some level because the band level had developed a very interesting adaptation against hierarchy. I don’t know if you’ve read Chris Boehm’s book, Hierarchy in the Forest?

Jordan Hall: I have.

Jim Rutt: Wonderful! If you want to think about humanity and organization and all this, read Chris Boehm’s Hierarchy in the Jungle. Really, it should be titled Non-Hierarchy in the Jungle because his thesis based on a lot of work is that band level Homo sapiens, Dunbar number and below had developed essentially everywhere on Earth an allergy to hierarchy, to bosses, to big shots and this is somewhat in opposition to our genetic heritage. Chimps are very hierarchical animals and probably band level humans had the genetic tendency towards relatively rigid hierarchy but Chris’ suggests it was the development of weaponry that allowed two betas to kill an alpha which allowed the band to essentially develop an ethos against hierarchy. When the Game A complex came into being and the way it transitioned above the Dunbar Number, was to develop hierarchical technology mediated with essentially praetorian guards or a small military caste that was very loyal to the leaders that could finally break out of the anti-hierarchical operating system that we had at the band level.

Jordan Hall: Yup. That’s right. That is definitely my perspective and I think more abstractly, what I would say is that at the band level we actually have a, maybe call like a formal closure over defection at least beyond a level that would be catastrophic to the group. Hierarchical defection is one example. You also have laziness defection is another example and band level groups are extraordinarily, like extraordinarily effective at policing defection inside the group. I mean defection here in the classic game theoretic sense.

Jim Rutt: Free riders. As we know, every system of cooperation is subject to erosion via free riders.

Jordan Hall: Yeah. My proposition is that in many ways, what we’re looking at in the Dunbar complex, and here I’m going to use the phrase Dunbar limit or the Dunbar complex, the set of would appears to be even the neurological capacities to engage in really robust modeling of every other member and all of the complex of relationships between the members. I would propose is in fact, evolution being sensitive to the catastrophic effects of defection in cooperation environments. Essentially, every human group that couldn’t police that little detection well enough would eventually find itself beginning some degradation of collective intelligence. It was essentially catastrophic to collective intelligence and therefore be selected again.

Jordan Hall: Over a long enough period of time, this Dunbar complex emerged and enabled the band level to endure against defection from individual members. It was [inaudible 00:23:15] by the way is a primary problem with Game A.

Jim Rutt: Interesting. I’ve long thought that homo sapiens sapiens even probably started at less than 150 and as we had this increased neocortex, that was the apparatus that allowed us to essentially do the combinatorics to get up to around 150 and while we didn’t have hierarchy in the jungle, we certainly had a band level rating in warfare often to the point of extinction. A band that could have coherence at 150 had a very substantial advantage over a band that could only have coherence at 80 and so there was a group selection advantage; yeah, I realized group selection is very controversial but I’m going to assume that it occurs, and hence there was a ratchet for more neocortex until the limit of the pelvic girdle in the human female was reached and that basically was how he converged to the Dunbar number of 150.

Jordan Hall: Yeah. I think we’re, more or less, in agreement around that story.

Jim Rutt: All right. We’re up to Jericho, 10,000 years ago approximately. Take the story forward.

Jordan Hall: Now what we look at is we have the story of history, essentially now. The story of Game A is the story of history and it appears that there’s roughly … Well, it’s called Three Plus One and we can say four but you’ll see why I’m calling it three plus one, failure conditions that seemed to just constantly show up in the construct of Game A.

Jordan Hall: One is the one we’ve actually been spending some time on which is detection. The band level doesn’t go away. It just gets subsumed in a larger construct and we see this, for example, in say how family groups might have a group selection advantage inside a society; Bush’s and Clinton’s being American examples but of course history is rife with this fact. I think from the warring states period in China, so like a hundred Chinese families represent 80% of the population. The Mafia there’s another great example where you can actually have inside a relatively large Game A society and I guess in a moment, I’ll have to give a bit more detail but what that looks like what it means.

Jordan Hall: You’ll still have all of these band level constructs going on and one of the problems that you run into is policing defection. It appears that, for very specific reasons having to do with the relationship between the complicated in the complex which I’ll go into in a moment, Game A is fundamentally vulnerable to defection such that no Game A construct will ever long endure. It will always eventually collapse either as a result of defection or as a result of the mechanisms that are used to police defection.

Jordan Hall: To zoom in on that piece, we can say that some primary characteristics of the Game A toolkit or what I would call society and identity. The notion here, what I mean by the concepts of society, is formal as opposed to organic relationship. The trash man as an example of society. The server at MacDonald’s is an example of society where there’s a formal relationship that has a bunch of social mechanisms that enables a human being to interact with another human being to accomplish a particular objective without having any human relationality in any sort of Dunbar level relationality with that individual. That’s the whole essence of society is that capacities, it’s how it’s able to scale.

Jim Rutt: Yeah, social roles. In a hunter-gatherer band everybody’s a generalist. They may have some special skills, “I’m a little bit better at flint knapping than you are but we can all knock flint a little bit, we can all hunt, we can all gather fruit when that’s in season.” The first sign of the more advanced societies is specialization and essentially the ammunition frankly of the richness of the individual.

Jordan Hall: We should be very precise also the notion of formal specialization which is, I think, very distinct from the kinds of specialization that you were mentioning. The specialization that you see if the band level is a very fluid meritocratic specialization, “Oh, you’re better at flint knapping so you’ll focus on that and I’ll focus on something else.” To the degree to which maybe something happens where your flint knapping either isn’t up to par or something shifted, we’ll just move. It’s not locked into anything because there’s nothing to lock it into. When suddenly you get the construct where the formal role, say priest or King exists, then you get this really interesting possibility on occasion.

Jordan Hall: I’ll use Game of Thrones as a metaphor assuming one, ubiquitous understanding of Game of Thrones by every human being on the planet and two, that it’s a useful metaphor. You get Joffrey. You get shit heads as kings. The meritocratic capacity is actually now blunted by the presencing or the existence of a formal structure that can take precedence over the quality of the individuals to actually do the role they’re in. This, by the way, will show up as being quite catastrophic in the second category but it’s helpful to just note that the society has that.

Jim Rutt: Yeah, think about the most generate examples where societies become caste societies like Indian Northern India and Japan where some lineages are said to be the hereditary slaughterhouse people and this other lineage is the hereditary trash people. We all know there’s grossly large amounts of genetic variation even within relatively small populations. The idea that a lineage is optimized for being slaughterhouse workers over a thousand years is utterly insane. One, a lot of them aren’t going to be good slaughterhouse workers and a whole bunch of other ones would be really good at other things like science or business or warfare or something. The caste system societies are probably the most degenerate example of social roles being reified to the point they’re unbelievably rigid.

Jordan Hall: Yep. The fundamental characteristic of Game A is this notion of society, which is a matrix of social roles that are formal in nature and then of course, the set of architectures and mechanisms for; A, creating the social roles, for apportioning individuals to social roles to the degree to which one needs to move somebody from a social role that exists as well and then bringing those roles into relationship. Of course, you’ve got many, many, many different variations of that over time. Feudalism, capitalism and say, classical slavery are all variations on that theme. They all satisfy those core functions using different techniques but the core functions are the same core functions.

Jordan Hall: The inverse of that or so the other element is this notion of identity; so you have the group which is now manifesting as society and you have the individual which is now manifesting as identity. This is also intrinsic to Game A where there’s an over coding or an additional element that is added to a human that is more than who they are as a human in kind of the way that said the bands really just absolutely, fundamentally knew each individual as a singular event in the universe. There’s no two of that person as is the case of every person but now there’s actually an identity which has a relatively generic content, and by the way], a relatively finite content. I am a Mason. I am the son of the King. Fill in the blank, any sort of finite semantic articulation is the content of identity and identity in society plug in to each other and it’s a key element of Game A.

Jim Rutt: Is identity anything more than the label of the cells in society?

Jordan Hall: Not really. You can see them going in both directions. On the one hand, the identity side of the pole is the degree to which Game A is territorializing or ingesting the band level human from the bottom up. The role of father as opposed to just merely being a father is an example of that level. It may not be that there’s an encoded structure like documents and whether it really says fatherhood, it contains these elements. It may be actually coming from the bottom up. For a long time, it may actually still most will be very natural and not formal. Society is more coming from the top-down. Coming from the direction of we, actually we, in some sense, can articulate and collectively point to, instead of very fundamental categories that dynamically the relationship between society and identity will begin the process of robustifying the number of labels that exist in society and expanding the content of work and being identity.

Jim Rutt: I like that. Could I play that back to you and tell me if you think I got it?

Jordan Hall: Yeah, absolutely.

Jim Rutt: Which is society ramifies over time. Every society cell, every role that a person can play in society is at least one-to-one correspondent to an identity. However, identity is broader because there can also be identities that aren’t necessarily yet been refined down to square pegs in society. Identity is a broader set of roles. Many of which are in society, and I would add as a hypothetical footnote, perhaps over time, the ratio of identities that correspond to society increases.

Jordan Hall: Yeah. That seems right, but it’s certainly we’re speaking about the same thing.

Jim Rutt: By this point, frankly in modern American society particularly for people who follow their nose through life, it’s essentially a one-to-one correspondence between identity and society. Damn close.

Jordan Hall: Something like that, yeah because society has become extraordinarily complicated.

Jim Rutt: Yeah. Anyway, continue with your story.

Jordan Hall: Okay. Now given these concepts of society and identity and you’ve used a lot of good terms like boxes and pegs and labels, the visual image to make this easy might be an XYZ cube with some number of relatively small cells in it, but it’s finite and it’s somewhat regular. Just to simplify. The point is that it’s complicated in the Dave Snowden sense. I’m just going to make a distinction between the complicated and the complex.

Jordan Hall: The complicated is a phenomenon that is finite and bounded in the world. If you contemplated for a moment, you realize that 100% of the complicated systems are human generated, sentient generated. An example might be, say, a Boeing 777 or a sailing vessel where there is, in fact, existent in actual impendium that includes all of the components of the Boeing 777. It’s vast. In fact, all of their specific relationships in appropriate operating parameters to the degree to which the Boeing 777 is functional. It is what is supposed to be. It is an extremely complicated system. But in principle, you could actually map all of it in a large enough database and you would be able to actually have a phase space that would include the totality.

Jim Rutt: I like Dave’s examples. What brought to life the nature of complicated for me at least very vividly, which is complicated as something that at least in principle could be taken apart and put back together again.

Jordan Hall: That’s very nice. Yeah, I like that a lot.

Jim Rutt: Yeah. I stole that from Dave. Thanks, Dave.

Jordan Hall: Yeah. That’s really nice. Then you cross over the other side of it and you have the complex, which as you say, could not be taken apart and put back together again. One of the characteristics of it is that the phase space is, at the very least, unbounded, which in principle, of course, means that in the forms of time, it is also at least in principle infinite, depending on your relationship to time itself that’s bounded. In relationship to human beings, the complex will have the characteristic of no particular finite database is for sure always going to be able to hold the phase space that describes the dynamics of that particular system.

Jordan Hall: The classic difference here you might say, a hummingbird where there’s things that are going on in the hummingbird that are fundamentally, in relationship both the microscale and the macroscale, with the whole of its ecosystem. There’s just an intrinsic connection between these two. The relationship with the causal movement up from the micro to the macro then causes the movements of the macro down, has a lot of stuff going on in the complex system dynamics. Small changes in subtle elements may actually lead to very significant changes in the larger system that are not just extremely difficult but actually histologically impossible to predict.

Jim Rutt: Conversely, a hummingbird is vastly more stable than a 777. A lot of things can actually go wrong in a hummingbird that’s actually alive and the complex top-down causality in multilevel loops can actually let the hummingbird fly even if it’s got a broken wing. It won’t fly well but it’ll figure out how to fly oftentime.

Jordan Hall: Exactly. To that exact point, society is fragile just like a Boeing 777. One of the problems that you run into, and in identity areas as well, is that in Game A no matter what you do, your society is going to be a complicated system and therefore, it is fragile in the sense that you just described, it is vulnerable to breaking apart as a result of changes in the physical environment, your society isn’t adopted to what’s happening in the world around it for example, but it’s also vulnerable to breaking apart due to corruption from the interior.

Jordan Hall: The difficulty of actually, say for example, policing defection behavior, you create a society, you create formal rules. You’ve got, say for example, the police. The police are a complicated structure endeavoring at the end of the day to manage the complex reality of human beings in the wild or human beings and their band level capacities. In the feedback loop between these two, as you endeavor to make a complicated system able to manage a complex system, what you’ll ultimately find is that as the complex system just mutates and changes and new possibilities emerge, the complicated system actually has to become more complicated.

Jordan Hall: In the software world, we know this is a kluge, the ability to go back in and do a completely architecture of a society in media’s rest while it’s in existence, it’s essentially non-existent. What ends up happening is you’re just going to add more things to it and you add more and more things to it. As you do this, what ends up happening is you start getting gaps and fissures in the closure of the society. These, of course, are exploited by the, call it the fungus or the MRSA of human socio-dynamics at the band level scale.

Jordan Hall: Are you familiar with the problem of fungus on the ISS?

Jim Rutt: No.

Jordan Hall: Apparently they have an extremely resilient fungus now in the space station. They just can’t fucking do anything about it because in the intensely complicated and unnatural environment of a space station, once the fungus mutated to the point where the things that they were able to use to kill it didn’t work anymore, they’re screwed and it can hide in the crevices and in the cracks and in places that are very hard to get to, and eventually, as our good friend, the guy from Jurassic Park, “Life will find a way.” No matter how much work you put into policing humanity’s capacity to try to figure out how to get an edge for their family, eventually somebody somewhere will find a way and then the gaps begin to emerge in the society. This begins a downward spiral, which many different people have actually studied. I actually first came across it in the context of a historian named Carroll Quigley, most recently in the context of a philosopher named Jean Baudrillard, who talks about in terms of these four stages of simulation.

Jordan Hall: More or less, the first catastrophe or the first problem that Game A runs into is the inability of society to fundamentally police defection from the bottom up in the context of actual complex human behavior over a long period of time. You will eventually get King’s Landing. You will eventually get some level of group selection. Here, I mean actually quite formally. I think that the culture evolution level, group selection is going to turn out to be the thing.

Jordan Hall: Some level group selection begins to emerge and you get this interesting transition. If we can zoom at the historical level, we see this happening all the time where for some period of time, let’s just take, say for example Roman history or American history for that matter. There’s a sense of their being a, call a well-functioning society where the individuals and the families and the band level groups more or less all participate in the commonwealth, in the common wheel. Defection is; one, not a particularly significant problem. Also two, is actually a police normatively. I think you and I talked about this a long time ago. Somebody who is shitty is just identified as shitty and is shunned normatively. Possibly, police harshly because their cultural memory of how imported is to maintain the integrity of society is strong.

Jim Rutt: Yeah. We talked about Peter Turchin and his asabiya concept, societies that have very high coherence and that anyone who’s a defector is very clearly a defector and is dealt with accordingly.

Jordan Hall: Yup. If you use the Game of Thrones story, if you remember in the North, the King of the North, that was a lesson. It’s the very first scene or so.

Jim Rutt: He had enforced his own moral system and the Young Wolf did the same thing. He was true to the virtue, “You violated the rules, I chop off your head.”

Jordan Hall: Who chops off the head? The King does.

Jim Rutt: Yeah. That’s the big difference between the North and King’s Landing. There is no headsman. The King himself takes the heads.

Jordan Hall: That, I think, is a great allegory of the general story of how this art goes. The further away you are, the more you are in society and the less you are in nature, the more you will the see the presence of this feedback loop between defection behavior and the capacity of society to police defection behavior. King’s Landing is far from the North, it is purely in society and so you begin to see the niche, actually. It’s just the niche of defection begin to emerge. Of course, what’s the story of that poker game? If you don’t know who the sucker is, it’s you?

Jim Rutt: Yes, one of my favorite sayings. If you’re sitting on a poker table and if you don’t know who the sucker is, it’s you. Same is true apparently in a commodity’s trading ecosystem. If you’re trading next year’s corn, if you don’t know who the sucker is, it’s you.

Jordan Hall: Yeah. There you go. Now this is probably not the case in the Seal Team, right? If you’re in the Seal Team, you’re looking right. You don’t know who the sucker is. You’re not even thinking rightly about being in the Seal Team as you probably reconsider your vocation. That’s the difference.

Jordan Hall: The difference is that in a context where the consequences of your actions are able to benefit you while generating externalities out into the environment, they can’t actually be brought back to you where you can actually open loops and create externalities in your social environment that benefit you and harm, essentially, other people by definition.

Jordan Hall: If that can’t be policed, then, bam! Game three pops into a “somebody’s a sucker,” and the question is who and Ned Stark gets his head cut off, and the downward spiral begins.

Jordan Hall: For some period of time, the pressure of nature and the original founding of the civilization has an inertia that endures but the inability to ultimately generate a hermetically sealed society, a complicated system, that can actually ultimately manage a complex system means that at some point, there will be a mutation, we’re discovering innovation in complexity that is able to begin to process of gaining the interiority of the society to the differential advantage of those mutants who have found that particular gain, and they will begin to have group selection advantage in the context of the society that they’re in which will inevitably lead to some balkanization interior and finally, the vaporization or collapse of the society.

Jim Rutt: Can certainly see that in the history of the late Roman Republic until finally, Julius Caesar and then Octavian brought it down once and for all.

Jordan Hall: Yeah. You can see what happen there was a massive system upgrade. Instead of [inaudible 00:41:30] the republic, they actually had to do sort of a hard reboot and launched entirely new society structure or fundamentally a new society structure. The history of China is even more clear. Maybe take a look at the story of each of the dynasties. It’s actually really rather astounding how cleanly they follow this tract where for three or four generations after the founding of the dynasty, you have a period of optimizing the social toolkit, the psycho-technology that that particular society is founded upon, generally some variation on the Confucianist toolkit, some new approach to how to do the mandarinate and the bureaucracy and whatnot.

Jordan Hall: Then after about three or four generations, you begin to see this group selection function in the emergence of new innovative capacities to get in between the cracks of that new social technology and begin to get a selective advantage for whoever happens to me. Maybe it’s the eunuchs, right? Maybe the eunuchs actually discovered there’s a way for them to actually gain the system. There’s an alliance between the eunuchs and the queens that generates a new group that’s able to actually get selective advantage in the context of the dynasty, and then the degradation the decadence begins and then the collapse, and then some period of dark ages and then a reboot of the new social structure.

Jim Rutt: While we move on with our story now, we’re still away from the present. Why don’t we move forward from the transition from Rome from the late republic to the empire and the cycles of the Chinese dynasties.

Jordan Hall: Okay. Move now to the second major problem that always faces Game A and then we’ll have most of what we need. Then the third, we can do pretty quickly and it’ll get us to the present. Is that good?

Jim Rutt: That sounds great. Let’s do it.

Jordan Hall: The second is our good friend Joseph Tainter and the stuff that he pointed out in his book, The Collapse of Complex Societies, and rebranded the collapse of complicated societies in more or less habit, which is that there is an expansion of technologies, capacities, social toolkits that will allow a given group of people to be able to meet their needs. They can get food, they can get water, they can … Whatever happens to be.

Jordan Hall: What happens is that, again this relationship between society and identity, the process of articulating these technologies has a certain carry on cost. Complicatedness is complicated. Somebody fucking needs to know how to actually build and maintain a Boeing 777. It’s like the whole lot of somebodies to be looking at that out there. As the infrastructure becomes more sophisticated, it actually becomes broader.

Jordan Hall: Initially, if we wanted to get oil out of the ground in Pennsylvania in the late 19th century, it may have just required a shovel and a bucket. By the time it gets to the deep water horizon, the complicatedness of that technical infrastructure become extraordinarily vast and it has an entropy. It actually requires a substantial amount of total carrying cost of resource just to maintain the physical infrastructure, which by the way is increasingly fragile as we saw in the impact of fragility goes up. That’s on one side.

Jordan Hall: Then on the individual side, in the identity side, the necessity of being able to load the information, to be able to be in a relationship to manage the complicated system requires an increasing degree of specialization in the individuals, which means of course an increasing lack of capacity to move sideways or down and over if there needs to be a change. If you’ve just spent the last 30 years becoming very, very skilled at managing, say, the Boeing … What’s the current one that became a [inaudible 00:44:47]?

Jim Rutt: 737 MAX, right?

Jordan Hall: If that’s what you’ve invested your time and energy in, you’re screwed right now because you have to go way back on your arc, learn a whole new set of skills, it depends on how mad it is but certainly, if we’re going to have the classic problem of an assembly line worker who, if car manufacturing shifts entirely to the totally new technical base, the assembly line worker is all the skills that they’ve built to be able to participate in that level of technical society, they’re obsolete and very, very difficult to retrain once you passed a certain developmental state.

Jordan Hall: What ends up happening is these two forces get locked into a feedback loop very similar, by the way, to the basic innovator’s dilemma inside the corporation. I think they’re, as far as I’m concerned, isomorphic. What happens is the society becomes addicted to its own tools that initially, they’re really fucking useful. For a little while, they actually go up that S-curve where they’re kicking ass and society is actually getting this huge boon of surplus capacity and energy that allows the society to grow a lot of different ways, most notably in population. But then the society finds itself addicted to its tools. It’s too over its skis. It’s got so many different constructs.

Jordan Hall: You got to think about oil in the world right now and you have pipelines all over the place, and you’ve got giant tankers that move back and forth, and you have a military industrial complex that maintains this integrity, the society regime, and you’ve got the petro dollar. Just think about the amount of shit that’s in place to maintain the integrity of the oil function in global society. Just run the clock back to the modest days, more or less about a century and a half ago of shovels and buckets of dirt. You can apply that to any society. You can take the Mayans. You can take the Chinese. You can take the Romans. It doesn’t matter. It has the same dynamic.

Jordan Hall: Then overlay all of these, all of these dynamics, on top of the fact that the underlying resource that the technology is optimized to extract is generally going to be either finite in quantity or finite in rate. Let’s say solar power as an example in the future. There is a finite flux of solar energy that hits the earth. It’s big but it’s finite like the oceans are finite, the amount of oil in the ground is finite. There is some point at which you have; A, pick the lower hanging fruit. As you pick the low hanging fruit, you have to actually upgrade your technical infrastructure to be able to continue to maintain just the same amount of supply. As your society has actually expanding its ability to take advantage of this boon, you generally could actually need an increase in supply.

Jordan Hall: You’d have to upgrade your technical infrastructure again. What will end up happening inevitably as Tainter points out, is that you get an S-curve happening at the level of innovation. At a certain point, it takes more energy per unit innovation and then that gives you an S-curve in just the actual throughput of your technical infrastructure. As you have been burned through the low hanging fruit, you end up getting this increasingly fragile relationship between the way that your society goes about meeting its needs and its relationship with the resources that happen to be in the ground. This then leads to, generally speaking, a collapse and then a reboot of an endeavor to be wiser next time with a more flexible social infrastructure.

Jordan Hall: If you look at, say for example, the collapse of Rome. You see both the corruption in the interior, now I’m in the Imperial Rome, call it 300, 400 AD with the constant turmoil of who wants to be Caesar in the general’s period. You have the fragility of the underlying infrastructure with the capacity to maintain the roads and the aqueducts and fill in the blank, the whole system becoming harder and harder and harder as more and more of the easy steps in the environment goes away and as the carrying cost of the infrastructure gets heavier and heavier. Of course, these two forces feedback on each other. When you’ve got really kickass, totally well-functioning bureaucracy, it can manage a complicated technical infrastructure. As the technical infrastructure gets heavier and heavier and as the bureaucracy becomes more and more corrupt and incompetent, you get a real problem. Go to visit Heathrow and you get a good sense of that.

Jim Rutt: I’ve done a lot of reading on the late empire and the collapse, and it fits right into your story which is the governance hierarchy became more and more corrupt and less and less efficient, and taxes got larger and larger and larger until a lot of the commerce, particularly in the economically wealthy eastern half of the empire, just shriveled under the impact of being looted by the local taxing authorities often sold the rights the so-called tax farmers. Low level, band level quasi criminals were operating in the name of the State to extract so much from the business community that it couldn’t function.

Jordan Hall: Yeah, exactly. You can see how there’s this really cool feedback loop where it really was, in fact, that complicated in bureaucracy that had just developed over time and the ability to come back and edit and keep it well-fit and well-pivoted and functioning is intrinsically hard. Then just add in a little bit of corruption, you get a really nice dynamic and it hollows Game A out from the inside.

Jordan Hall: Then you’ve got the third which is the world is not empty. There’s other people out there who were doing stuff. The Germans are sitting on the border, eventually able to have enough capacity on their own to hold back the expansion of the Roman Empire. Then for six generations, watching, stealing the best by the way, because stealing tech is much easier than innovating it and maintaining it, stealing the best tech from the Roman Empire, being much further or earlier in the curve of corruption. It’s still at a very high [inaudible 00:49:56], a very high level of policing defection, while Rome is becoming hollowed out within and so the bubble pops from the outside in this case and the barbarians come rushing in.

Jordan Hall: Of course, we see that as the third movement in history is that to the agree to which your civilization, your Game A structure, is able to maintain its capacity to feed itself, that it’s not having a Tainter curve lead to collapse along some relationship with nature, and to the degree to which it’s able to maintain its integrity and its interior and it isn’t being torn apart by corruption. It’s also having to go toe-to-toe with its neighbors who were trying to figure out how to steal the best from it and grow their own innovation. Of course, at some point perhaps that’s what causes your Game A civilization to collapse.

Jordan Hall: If you take a closer look at the Bronze Age collapse, the current thinking is it’s more or less all three. You had real maturity of the total construct of the Métis civilization, including the Hittites and Egyptians and Achaeans and whatnot. You had corruption that it gotten to rife levels across all of these different city states. You had real, significant environmental problems happening everywhere. You then have the migrations of these various barbarians and sea people and the bubble pops and the whole thing collapses.

Jordan Hall: More or less, Game A seems to have evolved through collapse. Its pressure, innovation, some expansion of some novel new approach that reaches a certain level then it collapses, but a lot of the innovations are living in the information domain and they don’t go away completely. Even the dark ages in Western Europe was really bad ultimately, much of Romans civilization was able to come back because it had been preserved, at least, adequately in the periphery and as the west got to a level it can begin to absorb it, it came back up. You got this ratchet.

Jim Rutt: It’s a long, long time. It’s longer than the Western Roman Empire existed. We didn’t recover the level of the Roman Empire probably at old 1750 or thereabouts. It was amazing.

Jordan Hall: Amazing, yeah. Yet at the end of the day, so far at least, we have. That’s where we are is this thing where Game A proceeds through this … I mean, this is a kind of evolution, right? It goes until it can’t and then it collapses as low as it needs to go until there’s enough stability that something new can begin to rise up. sometimes at the pan level again. Some meaningful portion of what was actually innovated in that previous structure isn’t lost, and so it gets brought back in, hooked up into a new system, and the new system enters back out into the world.

Jim Rutt: Why don’t you bring us up to date, when did the current instantiation of Game B get rolling, and where are we on this curve? Game A, I should say.

Jordan Hall: I get the sense that we have maybe two major points because it’s obviously a lot of different pieces that are going on that are interrelating. One major point is 1776. You’ve got the transition out of feudalism, in the west at least. The launching of all the consequences of the enlightenment into a civilization construct and you’ve got capitalism built into that construct. You’ve got liberalism, democracy built into that construct.

Jordan Hall: Then that construct, which of course had its mutation factors as it moved around the world, began to move around the world. You had an extension through the British Empire and then the collapse of the British Empire, and what I called the Victorian consensus around World War I, and interacting like a period of accountancy and exploration, World War II. Then pop! Finally, the 1950s post-war consensus where, as we know, a very large number of entirely new institutions in classic collapse rebuild showed up that were the most robust version of that particular instantiation of Game A toolkit. The enlightenment toolkit at its most robust level probably around 1977, actually, is I think where maybe it hit its peak, but starting in the 19 … Or probably right in the middle of World War II and extending to the late ’50s was when it was in the process of settling, and then it enters the expansion phase.

Jordan Hall: My current hypothesis is that by the late ’70s, it had begun the process of both the Tainter and the corruption process of moving from an acceleration to a velocity, meaning that the rate of advance was continuing, it was continuing to advance but the rate of advance was beginning to slow down. By the time you reach the fall of the Berlin Wall and the transition of China out of communism, you now have simultaneously and that it is rarely paradoxical, and we had the same thing happen with Rome where the flourishing of the early empire was also the death knell of the entire arc of the Roman story. By the late ’80s, George Herbert Walker Bush called it the New World Order?

Jim Rutt: New World Order, 1991 or thereabouts.

Jordan Hall: Was the point at which you have simultaneous the actual final flourishing and the success of this post-war toolkit, this last age of Game A, and the beginning of the process of its moving into decelerating velocity, from my perspective.

Jim Rutt: Also I would add, we seem to be getting close to the end of this epoch of Game A, we’re also confronted with some unique phenomena which is a very historically unusual exponential increase in capability, including the ability to destroy ourselves and we’re getting to the point where the cost of an individual to become super empowered in the Thomas L. Friedman sense keeps getting cheaper. Civilizations have run into their local ecological limits before Easter Island, the famous case, the Vikings on Greenland et cetera. We appear to be about to reach or maybe already have reached an overshot the worldwide ecological ability to support the style of life we have times 8 billion people soon to be 11.

Jordan Hall: Yeah. The process of gaining evolving through collapse has reached a point where that’s not a very good way of going forward. If you look at, even say the Roman collapse, at the end of the day, in the bigger scheme of things, even just in the bigger scheme of human things, wasn’t that big a deal. China was more or less doing fine during the Han period. Even in the area of just on the exterior periphery of Roman Lake, the Parthians were … They’re more or less happy to see what’s going on. Of course, the barbarians are doing their thing.

Jordan Hall: At a population level, the impact wasn’t that big. At a civilization level, certainly that region had a hard hit but at the level of humanity, no big deal. Now, for the very first time, we have something which is global, fully global, like every square inch of the planet is entrained. As you say, we now have access to a capacity to destroy that is orders and orders of magnitude greater. Back in the collapse of the Roman Empire, your capacity to kill people ended at the tip of your gladius. I suppose you could throw your javelin but the metaphor is funnier if it’s a gladius.

Jordan Hall: Nowadays, of course some variation between nuclear holocaust and CRISPR seems to be where we are now, but as you say, exponential change is a big deal, and so the capacity of smaller and smaller groups, so more and more people, being able to do more and more damage to an increasingly fragile social system is a real problem. The situation that we’re in in the context of Game A is unique in the history of Game A, and as far as I can tell, unique in the history of the world. Although maybe we can look at various serious epochs of, say, the transition from anaerobic to aerobic bacteria.

Jordan Hall: It may have been somewhat similar but the fact that we’re in a situation where the fragility of the overall system is high; at the ecological level, at the social level, we’ll get to that in a second. The technical capacity is astounding and proliferating, and the whole globe is entrained means that proceeding forward by ordinary Game A rules seems like a really bad idea, and using the concepts that we put in place, we can now begin to do some real diagnostics of what the fuck’s actually going on and say, “Oh. Oh, I see. We’re just at the end of a Game A story. A particular Game A story and perhaps, the whole Game A story.”

Jim Rutt: Yeah. It’s interesting. One thing I want to add is the structures we’ve built are historically unprecedentedly tall. You think about the internet running on 5 billion transistors per chip, fiber optics, worldwide networks, consuming vast amounts of power, et cetera. These are layers and layers and layers and layers of technology. If this thing starts to fall, it could fall a long way. It’s not like the Roman Empire where you can still go about farming if you’re a farmer. There’s an awful lot of things that we currently do that if we fell very far, you couldn’t do it all.

Jordan Hall: Yup, that’s right. I think that’s crucial. I remember reading Manuel DeLanda. I think it was called A Thousand Years of Nonlinear History. He pointed this exact point out that the structures that we’ve built are extraordinarily tall and therefore, even a small amount of fall has this capacity to fall a very long way. To make it very concrete, you could just think about the fact that there’s a lot of people. If there’s 8 billion people sitting on top of these very tall structures and the amount of pre-industrial farming, it was just going to fall that far which isn’t that far, it’s only a century. We’re not talking about something which is absurd. If we’re to fall just about a century and a half to pre-industrial farming, the amount of agricultural yield that we could produce would probably only be about a billion people because, by the way we’ve paved over a very large fraction of the variable land and sucked out a lot of the water that we otherwise be using. Who knows what the quality of the soil is without fertilizers?

Jordan Hall: That’s 7 billion people who don’t have food in that context. We should be quite clear that the 7 billion people probably aren’t all going to voluntarily walked into the hereafter. They may in fact struggle mightily over which get to be the one that makes it and many of them will have access to advanced technologies, and as we saw in World War II, but just think about this in terms of exponential technology. Take a look at 1938 level of military capacity and compare that to 1945 level of military capacity. I think more or less, any one of the nations that fought in World War II at 1945 level of technology could have taken on all over the rest of the world in 1938 level technology.

Jordan Hall: It just really went fast when the ship was hitting the fan. When all the marbles were being played before, we can move the ball forward pretty quickly, and to the degree which we find ourselves in the circumstance where more and more people begin to be aware of the degree to which all the marbles are being played for. We may actually see ourselves in an acceleration of capacity to fight that makes the relatively rapid pace of the past 20 years of peaceful capitalism look like nothing happened.

Jim Rutt: I would turn that around because you’re absolutely right, World War II is a wonderful example of, both wonderful and horrible example, but wonderful in the level of the human capability grew in that six-year period like it has never grown before including since then. Is it possible? Is it possible the techno-utopians are right that if we just keep pushing ahead faster and faster with our technological evolution, that the techno-evolution will get us through this coming crisis without a collapse? Is that possible?

Jordan Hall: Not in the context of the story of Game A that I’ve told. There’s every reason to believe that we have the capacity as humans to be able to, for example, manage the global ecosystem sustainably for everybody. There’s every reason to believe that that technical capacity is out there already present or not too far away. The problem is I think and it’s so funny how these things have happened. The story that I’m telling is the same story I’ve been telling now for about 15 years.

Jordan Hall: Now with, say for example, the Trump administration and as everybody well knows … I don’t have to point my finger at the Trump administration at the breakdown of collective sense making that is present everywhere, certainly in the west. Until we actually get to a point that we can resolve the intrinsic problems of the relationship between the complicated the complex and the nature of game theory in group selection, bigger tools aren’t the things that are going to help us. I’ll give you an example. I think we may even have talked about this on Facebook. I’ve certainly been talking about this with other people.

Jordan Hall: The degree to which the notion that climate change is either; A, not real; B, not a problem; C, not a problem the human beings have any need to take any particular role in; or D, in fact a malicious intentional effort to manipulate people to the degree which that category, that cluster of ideas, is propagating out into the global population into people who five years ago either thought nothing or thought the opposite is actually rather astounding. It’s significant.

Jordan Hall: By the way, I can’t blame them because we live in a world right now where those are all perfectly plausible because our capacity to engage in collaborative sense making is collapsing, and it’s part of the same story. Remember the story of the first thing that falls to Game A is society begins to become rife with defection and collaborative sense making is part of collective intelligence. It’s a resource essentially. Now, one of the first things that you’re going to do if you are in the process of trying to engage in group selection inside the larger society is take advantage of the gaps in social level collective sense making and defect using those techniques, otherwise known as marketing and propaganda, and spin, and fad.

Jim Rutt: Fake news, right? Troll armies, right?

Jordan Hall: Actually as a kid, I remember this feeling that happened in societies somewhere in the 1970s, somewhere early in the 1970s where it became more and more permissible to lie in public. I had this feeling of a commercial on television was telling me a lie and then the very next scene was like Richard Nixon telling me a lie, and then the adults around me were okay with that. The notion that in society, lying was a thing that was done relatively commonly, that was the beginning of a process of fertilization of culture. That’s just part of the whole story. That’s just the same thing as what’s going on with the Mafia who tries to take advantage of its advantages vis-à-vis old-fashioned policing.

Jordan Hall: In some sense yes, the techno-utopians are vaguely pulling in the right direction but we need to be very clear that it’s not going to be an extension of the 1950’s version of technology. It isn’t Mars. That’s for sure. It’s more like the technologies of civilization itself. We actually have to have a level up of the toolbox of civilization from the one that we’ve now been sitting on for 25,000 years or so, the Game A toolbox we’ve been talking about, into some new really radically different, fundamentally different approach to how we go about doing this civilization thing altogether.

Jordan Hall: John Vervaeke came at it from the angle of what he’s calling the Meaning Crisis. I think everything he’s talking about is 100% true and it’s just under the piece, from my perspective, of the same story. He talks about it as the necessity to construct a new set of psycho-technologies that are clearly novel, as novel as the ones that we’ve developed in the past.

Jim Rutt: We’re now up to the present day where the Game A system in your model and your view has become mature and corruption has flourished. You and I, I remember when we first met, I remember mentioning that when I first got in the business world in 1975, most of the people, at least I dealt with, were relatively honorable and honest and there were things that were profitable to do that they didn’t do because they were wrong. You said, as I recall, that you’d entered the business world about 1994 maybe, something like that. By that point, that concept was risible. The ethos of the business is if it was arguably legal and profitable, not only should you do it but you must do it.

Jim Rutt: We’ve now reached even more degenerate state where is it profitable? It may not even be arguably legal, but the penalties for getting caught are less than the profit. I mean, the recent $5 billion hand slap of Facebook is a perfect example of that. We’re in the late stages where the corrupt gangs are running rampant. The other one, you and I have certainly talked about plenty, is in the 2007 timeframe finance broadly construed was consuming 41% of the corporate profits in the whole U.S. economy.

Jim Rutt: Here’s essentially a ministerial function that is supposed to be a helper to the real economy is now eating 41% of the whole economy and even worse is sucking the best and brightest into doing that. When I see really smart people getting sucked into finance, it just strikes me as a horrendous loss and it strikes me that’s another symptom of your hypothesis that the fungus has run amok at this stage in our cycle.

Jordan Hall: Absolutely. You can even just see it in the tenor of the aesthetics, of the sensibility of when that was happening. The feeling of local group selection, like, “Yeah, I can get mine and I’m going to get mine. By the way, I’m going to get mine in the fashion which is simultaneously maximizing my local advantage and damn the externalities.” Wolf of Wall Street tells that story quite nicely. That’s just good old-fashioned defection on the larger social field. It’s not, “Now that I’ve got the structure to talk about, I’m like, “Yup. Now that’s it. That’s what you would expect to see.”

Jim Rutt: In our western … Let’s call it the democratic liberal model which always strikes me as the hopeful alternative. In theory, our political sphere is supposed to deal with these kinds of large-scale corruptions. You have the idea of finance, rigging the system for their own benefit, manufacturing opacity to enrich themselves et cetera, but of course in our late stage Game A, we have our politics has been essentially co-opted by money in politics and/or big media in politics so that the corrective mechanism that could be there isn’t there anymore.

Jordan Hall: Yup. I think we can come to a pretty fine point because it looks like, from my perspective at least, the way that I myself been modeling this and taking a look at the larger global system, it seems for example, that say China will have maybe the last gasp of Game A. It’s actually pretty funny that they’ve selected social credit as their variation because think about that in the language of complexity and complication, it is exactly a perfect effort to maximize complication in the effort to manage complexity.

Jim Rutt: Yes. We can have a large number of highly policed social cells and a large number of rigorously defined social identities that are not only defined subjectively but soon, quantitatively.

Jordan Hall: Yeah. We can now run it in a computational substrate using larger and larger degrees of increased and sophisticated A.I. to endeavor to manage the human choice making the human beings and so you’re going to get a proliferation that we would call like social granularity that will probably be many orders of magnitude, maybe even like five or six orders of magnitude larger than what we’ve seen in early 21st century America.

Jordan Hall: If my model of Game A is correct, then it’s going to collapse. By the way, if we’re looking at what happens in an exponential change arc, it will actually collapse in a relatively brief timeframe. I personally give them about seven years. That isn’t very long for the Xia dynasty in the context of the previous Chinese dynasty. The story that I’m noticing is that we have a … I’ve always been thinking there’s almost like a bridge, and then what’s on the other side?

Jim Rutt: Let’s pause here for a second. For the audience, say, hey, we’ve gotten up to date on Game A. Then you have also synthesized, I would actually help a little bit, in the early days, synthesized something called Game B which is an alternative for what might come next. You want to talk about that a little bit? Some of your admittedly rougher thoughts but they’re getting richer by the day, thoughts on where do we go next.

Jordan Hall: Yeah. Game B is notoriously difficult to think and talk about for the very good reason that if you were using the conceptual structures that came out of Game A to do so, you may very well be poisoning the well. Fortunately, in the context of what John’s been doing, I’ve actually got a new way of thinking about it, but you actually have to find a meta psycho-technology place to be able to do the meta design for psycho-technologies, to actually then come back down to the level of doing the psycho-technologies of Game B, which would be in principle now at this point distinct from the psycho-technologies of Game A.

Jordan Hall: That’s actually a huge insight. I don’t know if I … it’s a big deal for me. I don’t know if I’ve articulated even vaguely useful [inaudible 01:09:33] … Let back up, Game B.

Jordan Hall: All right. The hypothesis is that the innovation of Game A has now the zest of three plus one, and by the way, the plus one is the problem of exponential technology. You just brought it in but it’s a problem on its own and it has an end point of its own. It looks like we’re reaching the end. On the one hand, you can take a look at Game A and say, “Okay. Any given instantiation has a finite lifespan to it and also that it appears that all set of Game A instantiations have a finite lifespan to them, and also it looks like we’re getting to the end of it.”

Jordan Hall: It may in fact be requisite that we make the extraordinarily challenging move of trying to level up a whole new collective intelligence toolkit at the same level of magnitude as the movement to the band/tribal level of collective intelligence and the Game A level of collective intelligence. That’s something that comes around every 30,000 years or so. That’s a good way of setting the stage for the level of challenge of endeavoring to construct something of that sort. But if it’s what we have to do, it’s what we have to do.

Jordan Hall: Fortunately, we’ve come a long way. We’re actually quite sophisticated as a species in thinking about these kinds of things in comparison, say to for example, the big reboot that happened in 1776. The enlightenment gave birth to what I would say is now the last stage of Game A or close to it and that was a pretty big deal. That’s actually pretty major shifts they made from late stage feudalism to early stage liberalism. In the move from Game A to Game B, we’re looking at something which is similar in kind, just maybe three orders of magnitude larger in magnetic or in difficulty.

Jordan Hall: In that language then, one of the characteristics of Game B has to be that it can’t be constrained by the problem of complication. It doesn’t solve the problems of human needs through the construction of complicated systems. It doesn’t use either society or identity to do the things that it does. Now, this of course, the very first blush has all kinds of consequences and [inaudible 01:11:27] demoralizes a lot of people because it feels like that can’t be done. But we can take a look back and say, “Okay. We did do this at least up to the scale of the Dunbar limit back at the previous iteration.” The band level of collective intelligence was running in complexity. It wasn’t running in complicatedness. I mean, into a degree which complicated things came up, they were relatively minor in the scheme of things. They’re still held in a way that didn’t fall into the pitfalls of danger or defection.

Jordan Hall: A way of stating it is how do we go about maintaining the level of coherence, the level of complexity as an intrinsic that we have at the band level and scaling that up to include will effectively, ultimately 8 billion people, but more than 150 initially. That was the statement of the problem. Literally, you and I came to, what? In 2013 or so?

Jim Rutt: Yup.

Jordan Hall: It’s still the same problem. That’s the nature of the beast. We can actually now get … The story hasn’t set still. Meaningfully more sophisticated in beginning to gesture in that direction. I hope that I can say it in a way that it works because I know in the past you’ve actually had some challenges with this, but it had to do with looking at the possibility of space in human psychology. The proposition is that we have actually concretely, and this is where again I’m going to continue to refer to John because he’s a 4th generation or whatever, nth generation cognitive scientist.

Jim Rutt: Jordan, let me just drop in here for the edification for our audience that the original attempt to build a Game B was probably too early, we didn’t know enough, but it also fell apart over an internal schism between, I would call, the personal change faction and the institution’s faction.

Jim Rutt: One group thought that Game B could be reached by making better people, and the other group rejected that and said, “No, it has to be by building better institutions.” I haven’t been very involved with it for the last five years but just occasionally, check in with Jordan and his friends. Duh, it’s the usual social science answer. Both, right? Nurture versus nature. Both, right? This false distinction and the civil war that the earliest version of Game B fell into on personal change versus institutions, I am now perfectly happy with both.

Jordan Hall: Well, that’s amazing. All right. That’s really good because I have come to the conclusion that it’s absolutely both and quite frankly concretely because in some sense, the good news is that the level of making better people, it’s really not a whole lot about making better people, it’s making less shitty people. The tragedy, I would say the primary tragedy of Game A is how enormously it has screwed up humans in many, many different ways.

Jordan Hall: Obviously, if you go back into the beginning, you look at this human lifespan got cut in about a third. Then you can take a look now and just take a look at the, what I would consider to be nearly holocaust level nastiness of what is happening to the psychology of every single child who is put through school, the degree to which we’re destroying the capacities of human beings at industrial scale, at the level of their psychology is really rather significant.

Jordan Hall: What I’ve discovered over the past five years is that while remediating that damage and bringing people frankly, back to the basic capacity to be mature adults who can use the whole of their mind to be thinking, and not simulated thinking, is really quite hard. This healing piece is a massive issue. I myself have been struggling with that since … Well, perhaps 2012 and it still have ways to go. That’s a big problem. The humanity that we are working with right now, I would say is maybe operating at about 10% of the capacity of just normal human beings.

Jordan Hall: Then of course we actually have some pretty high quality stuff to take it up a notch. Not a lot, like we’re not talking about going up 50% but taking it up, say, 7% at the level of, say, how children are parented. We have much more sophisticated capacity to actually know what the developmental stages are and what kinds of things are appropriate, certain developmental stages at the level of nutrition and things like that.

Jordan Hall: Now moving into the institutional side, there’s like the mesh between those two is the institutional fabric that sits on top of human development and human relationship. I was just yesterday having a chat with somebody who has what appears to be some really sophisticated technology for how groups of individuals who have very distinct perspectives, meaning even to the level of distinct epistemological frameworks, can actually be facilitated into extremely effective collective intelligence. The stuff that SFI found this of having to deal with, but at a much higher level. Quite diversely, you could grab a Christian fundamentalist and put him in a room with an atheist. Well, as a part of a group of seven. Through this facilitation process actually gets something which has a truly functional collective intelligence.

Jordan Hall: This is an example of a technology. Frankly, it’s a psycho-technology. The collection of; A, what I would call maybe the technologies of healing or the technologies of sovereignty that bring human beings up to the level of being able to simply participate, being able to say be not triggered by things that make them emotionally triggered or to be able to not be bound to a particular way of saying things but able to try to listen to what is being said thoughtfully in wonder and curiosity about what might be possible even if what’s being said is nonsense, just trying to listen to anything that could be useful. That set techniques has been already worked through. We just got to collect them and bring them together, throw out the trash because there’s still a lot of trash but there’s people out there who’ve been doing that work now for decades and it’s not bad. It’s a lot better than it was in say, 1910.

Jordan Hall: Then the set of technologies that are associated with bringing groups together in deliberative process of being able to actually get a synergistic capacity, a whole that is much larger in some of the parts in collective intelligence.

Jordan Hall: Also, there’s a lot and they’re pretty good. I’m currently in the process of actually going out in first person experiencing a number of them, and then endeavoring to find a way to curate the ones that are the most effective, and then recursively using them to bring groups together using these techniques to then give insight into what might be a deeper and better way of doing it.

Jordan Hall: Then the third piece, which I think is actually rather interesting, is the inverse of this problem of the globalization of civilization. That’s that, in principle, everybody can be involved. You can find the right people. Imagine if Facebook didn’t suck.

Jim Rutt: Dream on, White boy.

Jordan Hall: Isn’t it astounding like how extraordinarily Facebook suck? Actually, if you thought about the potential. Just think about this, you know Ramanujan, right? You know the story of him.

Jim Rutt: Yeah, the mathematician.

Jordan Hall: The mathematician. For the listeners, we had this really great story of this guy who was way, way off the charts, asymmetric genius in mathematics. It happened to be an Indian guy in the, I guess, the early 20th century. In a timeframe in the context where almost all ordinary paths would have had him being just maybe working at the post office and nothing happens. It’s almost sure circumstance he happens to run into a guy who knows a guy who can get him connected up to Oxford. They send a paper over. It gets read. The guys at Oxford actually are legitimately and honorable, interesting, curious people. They read it. That’s amazing. They pull his ass out of India, and bam, he delivers just genius into the mathematical discipline.

Jordan Hall: Well in 1910, 1920, that’s almost a random event but in 2020, in principle with very limited exceptions, you could do that for every Ramanujan. Everywhere. You could find these people. You could find every single person who has unique asymmetric information or capacity and you could, by the way, bring them in relationship with technologies from the first two buckets. You could actually help them increase their capacity to give what they have to the world by solving whatever happens to have been bends and bumps in the developmental arc and bring them into collective intelligence with sophisticated technologists to support that, and boom! Now you’ve got something that could really do things in a huge way.

Jordan Hall: Now, you’re using humanity’s capacities to our advantage. I honestly think we’re not one of these … was it Tantalus? We’re not that far away from this. Unfortunately, we’re chained to this rock of Game A so we can’t quite get to it but in terms of the actual reach, the possibility of putting together a collective intelligence that has the capacity to generate the meta psycho-technologies that would then give us the capacity to generate these psycho-technologies to birth Game B is right there and it’s right in front of us. It’s not that far away. More or less, we just have to get over ourselves.

Jim Rutt: Okay. Let’s say you do that. Let’s say you finish your curation turn and you come up with five very cool psycho-technologies that brought together, produced really powerful small groups to medium-sized groups of people for solving problems, but you’re just 150 hippies, right? You got Goliath. Last night, I watched the democratic debate. What a shit show, right? Compound idiocy to the 4th power. What the fuck? We’re a million miles from innovative thinking about anything.

Jim Rutt: How does your 150 hippies who figured out the right way to do it basically gather the levers of power and more specifically, let’s just say the levers of power we find a way to make them go away but fundamentally, a society is about a flux of energy in the actual physics sense because it’s energy that causes us to deplete our ecosystem and it’s the means by which we deplete our ecosystem. How do your 150 hippies gain control of the energy flux of 8 billion people before the whole shit show collapses? To put it in very bland and mild terminology.

Jordan Hall: By the way, I will now publicly tell everybody that my recommendations should be called the Jim Rutt Experience, harking back to the Jimi Hendrix Experience but you’re doing the thing you’re supposed to do and it’s good. Thank you.

Jordan Hall: Yeah. Obviously you and I have talked about this particular question quite a bit. Even just this morning, I was sharpening my tools in terms of imploding the entire global financial system and getting rid of money because you may have to go there, but let’s be a little bit more abstract first and then come back down to the tactical … Strategic before tactical.

Jordan Hall: Strategically, I would like to make two changes to your formulation. First, it can’t be 150. It’s probably going to be more like 1,500 to 3,000. Second, I’d replace the term hippie with something like Vulcan Spartans or something like that.

Jim Rutt: Okay. That’s fair enough. Let’s remap it to the population of a tiny county in rural Virginia. Let’s call it 2,500 and let’s call them Vulcans.

Jordan Hall: Vulcan Spartans, my friend. You have to have both.

Jim Rutt: Got to have both. Even better.

Jordan Hall: The theory, and by the way, this is actually being run from a theoretical level. The theory points to two possible paths that are viable. The first path is the friendliest path, so I’ll just go in that direction. It looks a lot like early Christianity with a lot less bloodshed and on an exponential growth curve. The ability of individuals to opt out of Game A and opt into something else is in the west, at least, relatively open to the degree to which you can actually design something that is complete. By that I mean it is a fully functioning though small in scale but also scalable, instantiation of Game B.

Jordan Hall: Now, I’ve got my city state in … Where were we in? Virginia? Highland County? I’ve got a city in Highland County and it’s small. It’s somewhere in the range of a village to small town but it has all of it. It has kids being born, it has kids going to school, it has old people, it has people dying, it has food production, it has energy. For the moment, it even has an interface layer with Game A but it has an interface layer that is operating on an asymmetric advantage.

Jordan Hall: Think of it as like Google village where the capacity to be able to generate high-value product into Game A is asymmetrically high, and so that produces the output that generates the influx of resources necessary to be able to get the things you can’t get out of the community but the community is constantly looking for ways to use its capacities and its relationship with the larger world to become increasingly local and increasingly autonomous.

Jordan Hall: Think of it almost like an effort to construct a Mars colony in Highland County. Just imagine you had something like that. Then imagine that you had a mechanism whereby human beings could either choose to, A, immigrate, by the way, under very specific parameters, or B, could actually copy this entire sociotechnical infrastructure and endeavor to launch their own in their own environment using the same, by the way, immigration protocols because obviously a key piece of the psycho-technology is how does somebody actually become capable of participating in this symmetrically.

Jordan Hall: True to the degree to which this simple choice for a very large number of people to begin the process of playing this Game Becomes an easy yes, either because their current circumstances, let’s say like West Baltimore or North Baltimore, wherever now in Baltimore they happen to be or … Well, frankly, all over the place exists.

Jim Rutt: I would say shit San Francisco. What a shit show that place has become.

Jordan Hall: San Francisco is a really good example, right? From a design perspective, the challenges that you have are how far away are the individuals from their capacity to participate in a wholesome fashion. What’s the amount of healing that has to be done before that you have a critical mass of people that can actually participate? How many can be brought in to an existing context at what rate without destabilizing the coherence of the existing system? At the primary rate limiters, how rapidly can you … well, what do you start with in terms of where people are coming from? How rapidly can you heal them of the things that prevent them from being able to participate as just a good citizen, and how rapidly can they be integrated into an existing coherence without disrupting their career? Those are the three great variables.

Jordan Hall: Right now, there’s actually a pretty sizable population of people who are not that far away. They are still pretty healthy, honorable, honest, good folk who, if they just had an opportunity to be able to do the things that they know are right without being fucked over or just overburdened by bureaucracy or corruption, would choose to do so. Whether you think that’s 4 million or you think it’s 70 million, somewhere, it’s certainly more than 2,000.

Jordan Hall: If the psycho-technology are not radically difficult for people to learn how to get into, just take a look at the challenges of immigration that happened in the United States in the period between, say, 1840 and 1940. My great-grandfather, or maybe great-great but something in that order, was like nine and spoke Russian and it was on a boat by himself and landed in Galveston, Texas and became the rising shopkeeper in the art of his life.

Jordan Hall: The capacity of people to immigrate and upgrade into new psycho-technologies is historically actually not radically difficult. It isn’t easy but it’s not radically difficult. That’s path one. Path one is, basically, you build something that is complete, that actually has all the stuff. This is important because if it’s not complete at a complex systems level, then you may be throwing externalities you don’t understand the actions to be homeostatic and has the ability to at least perceive the loop that it’s connecting with. It doesn’t have to be completely close. You just have to include all the aspects.

Jordan Hall: Then you begin the process of immigration and scaling. You scale both organically directly in that location, and also to the degree to which you can actually have this to be very [prototypable 01:26:46] or let’s say, for example, you don’t launch the first one in San Francisco. You launched the first one in Virginia, but then a group from San Francisco comes and wants to try and you have, say, 40 people from San Francisco come, live in this environment for a couple of years until they’ve really in their cells have absorbed the culture and all the techniques and technologies that have to be brought. They then go out and maybe 40 people go with them, like good old-fashioned Greek City States had that characteristic.

Jim Rutt: By the way, there’s actually two great precedents I can think of. The biggest one, historically, that’s how the hunter-gatherer bands did it. They didn’t clone themselves. They just got to the point where they were too big for their business model and they fissioned. Maybe you don’t think about cloning but rather you think about fissioning. It may be that the fission component decides to go to San Francisco, part of the ethos of spreading.

Jim Rutt: The other example, modern day are like Mennonites. A whole families of Mennonites pack up from Pennsylvania and move to Mexico. There are Mennonites in Mexico. There are now Mennonites in Highland County, Virginia who some of them came down from Canada, right? Think about it rather than planting colonies externally, you bud them off from the mothership, and then those of course bud off and you have an exponential growth, right?

Jordan Hall: I’ve mentioned John Vervaeke in the past a few times. Remember I mentioned that he’s characterizing it as awakening from the meaning crisis. I think one of the things that is obvious, I think … at least wasn’t to us back when we’re talking about the past. One of the primary values, one of the primary things that a person will notice when they’re participating in this Game B environment is a radical upgrade and the meaningfulness of their lived experience. Their life will in fact be and feel meaningful.

Jordan Hall: That’s a primary currency of this culture. The invitation … you’re sitting in San Francisco, and yes, if you join this culture, you begin to participate in it and you get better friends who are more considerate and are more capable of interacting with you. You have the possibility of finding mates who are more likely to be better parents. You can actually raise better kids and fill in the blank all the things that are part of what just living a simple meaningful human life is all about and your day-to-day life will actually be felt and will be meaningful. That’s the thing that will of course make it rather attractive.

Jim Rutt: Of course that’s what Christianity grew from, right?

Jordan Hall: In Rome, yes.

Jim Rutt: There was into my mind a bogus meaning but it was a meaning that was large scale and attractive.

Jordan Hall: Well, I mean, parts of it were bogus but I mean in the context of early Christianity, you were living in a society where throwing people to the lions was entertainment for everyone. The Christians were actually entering into a context where the people around them were not likely to stab them in the eyeball for accidently forgetting their lunch. That’s a pretty significant real upgrade in the quality of your life.

Jim Rutt: Yeah. The community was good. I was just arguing that their metaphysics was baloney, but it may be irrelevant actually as it turns out, whether the metaphysics is baloney or not.

Jordan Hall: Well, this is one of the interesting things because what’s really neat about the story of Game B is that we also get the advantage of actually having a really seriously kick-ass metaphysics that is totally inclusive of the totality of all the cool stuff that scientism in the past 1,500 years, because we should, we need to, right? I mean, you just need to be in relationship with what is actually real and true is a really cool advantage. If you want a competitive advantage of a Game A in its current state, tell the truth and have the capacity to perceive reality with simple clarity and then convey that to other people.

Jordan Hall: This is one of the interesting insights I’ve been having now over the past three years is that a large piece of what happens in Game B is that it’s actually extremely simple, and actually kind of slow. It moves at a much slower pace because that’s almost like the pace of meaningfulness. Most of what you discover is that it’s shockingly simple. It’s just that the world that we’re living in is hyper, hyper-complicated, so we get confused.

Jordan Hall: Yet because of the … and this is I mean the last piece. Let me just put this last piece in and then we’ll probably just [inaudible 01:30:58] at least for the moment. By the way, there’s a whole another giant story to explain what I’m saying here but there’s very, very good reasons to believe that the kind of context that I’m talking about, the kind of thing that would be Game B would actually be vastly, vastly more, let’s call it competitive in old-fashioned Game A terms vis-à-vis Game A.

Jordan Hall: To just extract it a little bit, just give a little meat to that bone, if you look at the arc of Game A … just go with straight military history. It’s been very concrete. For a long time, military history was built around either physicality, or around tactics, or around a certain level of strategy and weaponry [inaudible 01:31:42]. Everyone once in a while, weaponry made a difference. Then they begin to see some movement in the [inaudible 01:31:47], not that long ago, where technology began to show up as playing an independent and increasingly important role in the story of how you actually beat the other guy.

Jim Rutt: About 1450 you can say, started to become significant.

Jordan Hall: Yeah. I mean, that’s not that long ago. Then of course you just fast forward and get to our World War II where the emergence of where they call the pointy-headed geeks or the pencil-necked geeks. I think they’re probably just talking about Alan Turing and the guys down at the Manhattan Project. Holy shit, like those guys actually won the war. It didn’t take long to realize that the capacity of the people who are capable of innovation has vastly outstripped physicality. That’s the outstripped tactics, and in fact, moving to the point where it’s going to be vastly outstripping all possible strategy.

Jordan Hall: I can speak about that in detail if you’d like, but the basic point is as it turns out, Game B actually also ends up being the theoretically optimal conditions for maximal innovation because it’s the theoretical optimal conditions for maximum creative collaboration. It also has this characteristic of having an escape velocity in techno-utopia space, but in a context where it doesn’t lead to the catastrophic consequences of exponential technology. There’s a lot there.

Jim Rutt: I think this has been wonderful, Jordan. Actually, I had high hopes for this session. As you know, I’ve always respected the work that you do. Occasionally, we argued sometimes violently, but this has been one of the most wonderful conversations I’ve had in a long time. We actually did do some thinking here, not just simulated thinking, and I thank you for this very, at the end of the day, hopeful discussion.

Jordan Hall: That’s beautiful, man. Thank you. My pleasure, my absolute pleasure.

Jim Rutt: Production services and audio editing by Stanton Media Lab. Music by Tom Muller at modernspacemusic.com.